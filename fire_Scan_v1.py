#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥å…·é›†ï¼šç«ç„°URLæ‰«æå·¥å…·
ä½œè€…ï¼šp1r07
ç‰ˆæœ¬ï¼š5.0.0ï¼ˆç«ç„°ä¸»é¢˜ä¼˜åŒ–ç‰ˆï¼‰
åŠŸèƒ½ï¼šURLæ‰«æä¸ICPå¤‡æ¡ˆæŸ¥è¯¢ï¼Œç«ç„°é£æ ¼å±•ç¤º
"""

import os
import sys
import subprocess
import pkg_resources
import requests
import socket
import csv
import time
import json
import asyncio
import aiohttp
import hashlib
import re
import base64
import random
import tldextract
from urllib.parse import urlparse, urlunparse
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad
from colorama import init, Fore, Style
import logging

# -------------------------- ä¾èµ–æ£€æŸ¥ --------------------------
def æ£€æŸ¥ä¾èµ–():
    """æ£€æŸ¥å¹¶ç¡®ä¿æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…"""
    required_packages = [
        'colorama>=0.4.6',
        'pycryptodome>=3.18.0',
        'tldextract>=3.4.0',
        'aiohttp>=3.8.4'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            pkg_resources.require(package)
        except:
            missing_packages.append(package.split('>=')[0])
    
    if missing_packages:
        print(f"{Fore.RED}æ£€æµ‹åˆ°ç¼ºå¤±çš„ä¾èµ–åŒ…: {', '.join(missing_packages)}{Style.RESET_ALL}")
        install_cmd = f"pip install {' '.join(missing_packages)}"
        print(f"è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…: {Fore.GREEN}{install_cmd}{Style.RESET_ALL}")
        sys.exit(1)

# é¢„å…ˆæ£€æŸ¥ä¾èµ–
æ£€æŸ¥ä¾èµ–()

# -------------------------- ç«ç„°ä¸»é¢˜é…ç½® --------------------------
# ç«ç„°ä¸»é¢˜é¢œè‰² - æ¨¡æ‹Ÿç«ç„°çš„çº¢ã€æ©™ã€é»„æ¸å˜
FIRE_COLORS = {
    "red": Fore.RED,
    "dark_red": Fore.LIGHTRED_EX,
    "orange": Fore.LIGHTYELLOW_EX,
    "yellow": Fore.YELLOW,
    "gold": Fore.LIGHTGREEN_EX,  # ç”¨äºé«˜äº®
    "blue": Fore.BLUE,
    "reset": Style.RESET_ALL
}

# ç«ç„°é£æ ¼å›¾æ ‡
FIRE_ICONS = {
    "flame": f"{FIRE_COLORS['red']}ğŸ”¥{FIRE_COLORS['reset']}",
    "spark": f"{FIRE_COLORS['orange']}âœ¨{FIRE_COLORS['reset']}",
    "success": f"{FIRE_COLORS['yellow']}âœ…{FIRE_COLORS['reset']}",
    "error": f"{FIRE_COLORS['red']}âŒ{FIRE_COLORS['reset']}",
    "info": f"{FIRE_COLORS['blue']}â„¹ï¸{FIRE_COLORS['reset']}",
    "warning": f"{FIRE_COLORS['orange']}âš ï¸{FIRE_COLORS['reset']}",
    "check": f"{FIRE_COLORS['yellow']}ğŸ”{FIRE_COLORS['reset']}",
    "icp": f"{FIRE_COLORS['blue']}ğŸ“‹{FIRE_COLORS['reset']}",
    "ip": f"{FIRE_COLORS['gold']}ğŸŒ{FIRE_COLORS['reset']}",
    "asn": f"{FIRE_COLORS['orange']}ğŸ”¢{FIRE_COLORS['reset']}",
    "isp": f"{FIRE_COLORS['yellow']}ğŸ“¡{FIRE_COLORS['reset']}",
    "csv": f"{FIRE_COLORS['gold']}ğŸ“Š{FIRE_COLORS['reset']}",
    "author": f"{FIRE_COLORS['dark_red']}ğŸ‘¤{FIRE_COLORS['reset']}"
}

# ç«ç„°åˆ†éš”çº¿
FIRE_SEPARATOR = f"{FIRE_COLORS['red']}-{FIRE_COLORS['orange']}-{FIRE_COLORS['yellow']}-" * 15

# -------------------------- åŸºç¡€é…ç½® --------------------------
# å·¥å…·æ ¸å¿ƒä¿¡æ¯
TOOL_NAME = "ç«ç„°URLæ‰«æå·¥å…·"
AUTHOR = "p1r07"
VERSION = "5.0.0"
MODIFY_TIME = "2024/05/26 14:20"

# è·¯å¾„é…ç½®
CSV_OUTPUT_DIR = os.path.expanduser(f"~/.fire_scan_results/{time.strftime('%Y%m%d')}")
os.makedirs(CSV_OUTPUT_DIR, exist_ok=True)
CACHE_DIR = os.path.expanduser("~/.fire_scan_cache")
os.makedirs(CACHE_DIR, exist_ok=True)

# é…ç½®å‚æ•°
DEFAULT_WORKERS = 3
DEFAULT_TIMEOUT = 15
RETRY_ATTEMPTS = 2
PRINT_DELAY = 0.05  # æ‰“å°å»¶è¿Ÿï¼Œè§£å†³é€Ÿåº¦è¿‡å¿«é—®é¢˜
CACHE_EXPIRE = {
    "icp": 86400,      # ICPä¿¡æ¯ç¼“å­˜24å°æ—¶
    "ip": 3600,        # IPä¿¡æ¯ç¼“å­˜1å°æ—¶
    "asn": 86400,      # ASNä¿¡æ¯ç¼“å­˜24å°æ—¶
    "dns": 300         # DNSè§£æç¼“å­˜5åˆ†é’Ÿ
}

# å¤šæºAPIé…ç½®
IP_INFO_APIS = [
    {
        "name": "ip-api",
        "url": "http://ip-api.com/json/{target}?fields=status,message,country,regionName,city,isp,org,as,asname,query",
        "timeout": 8,
        "success_key": "status",
        "success_value": "success",
        "mapping": {
            "country": "country",
            "region": "regionName",
            "city": "city",
            "isp": "isp",
            "org": "org",
            "asn": "as",
            "as_name": "asname",
            "ip": "query"
        }
    },
    {
        "name": "ipinfo",
        "url": "https://ipinfo.io/{target}/json",
        "timeout": 8,
        "mapping": {
            "country": "country",
            "region": "region",
            "city": "city",
            "isp": "org",
            "org": "org",
            "asn": lambda x: x.get("asn", "").split("AS")[1] if x.get("asn") else "",
            "as_name": lambda x: " ".join(x.get("asn", "").split(" ")[1:]) if x.get("asn") else "",
            "ip": "ip"
        }
    },
    {
        "name": "ip2location",
        "url": "https://api.ip2location.io/?ip={target}&key=demo",
        "timeout": 8,
        "success_key": "response",
        "success_value": "OK",
        "mapping": {
            "country": "country_name",
            "region": "region_name",
            "city": "city_name",
            "isp": "isp",
            "org": "domain",
            "asn": "asn",
            "as_name": "as",
            "ip": "ip"
        }
    },
    {
        "name": "taobao",
        "url": "https://ip.taobao.com/outGetIpInfo?ip={target}&accessKey=alibaba-inc",
        "timeout": 6,
        "success_key": "code",
        "success_value": 0,
        "data_key": "data",
        "mapping": {
            "country": "country",
            "region": "region",
            "city": "city",
            "isp": "isp",
            "org": "isp",
            "asn": None,
            "as_name": None,
            "ip": "ip"
        }
    }
]

# ICPå¤‡æ¡ˆæŸ¥è¯¢æº
ICP_QUERY_SOURCES = [
    {
        "name": "miit-official",
        "priority": 10,
        "reliable": True
    },
    {
        "name": "third-party-api1",
        "priority": 8,
        "reliable": False
    }
]

# æ—¥å¿—é…ç½®
init(autoreset=True)
logging.basicConfig(
    level=logging.INFO,
    format=f"{FIRE_COLORS['orange']}[%(asctime)s]{FIRE_COLORS['reset']} %(message)s",
    datefmt="%H:%M:%S",
    stream=sys.stdout
)
logger = logging.getLogger(TOOL_NAME)

# -------------------------- ç«ç„°Banner --------------------------
def æ‰“å°ç«ç„°Banner():
    """æ‰“å°ç«ç„°é£æ ¼çš„å·¥å…·Banner"""
    banner = f"""
{FIRE_COLORS['red']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—{FIRE_COLORS['orange']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— {FIRE_COLORS['yellow']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  {FIRE_COLORS['red']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— {FIRE_COLORS['orange']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
{FIRE_COLORS['red']}â–ˆâ–ˆâ•”â•â•â•â•â•{FIRE_COLORS['orange']}â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—{FIRE_COLORS['yellow']}â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—{FIRE_COLORS['red']}â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—{FIRE_COLORS['orange']}â–ˆâ–ˆâ•”â•â•â•â•â•
{FIRE_COLORS['red']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  {FIRE_COLORS['orange']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•{FIRE_COLORS['yellow']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•{FIRE_COLORS['red']}â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘{FIRE_COLORS['orange']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
{FIRE_COLORS['red']}â–ˆâ–ˆâ•”â•â•â•  {FIRE_COLORS['orange']}â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—{FIRE_COLORS['yellow']}â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—{FIRE_COLORS['red']}â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘{FIRE_COLORS['orange']}â–ˆâ–ˆâ•”â•â•â•  
{FIRE_COLORS['red']}â–ˆâ–ˆâ•‘     {FIRE_COLORS['orange']}â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘{FIRE_COLORS['yellow']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•{FIRE_COLORS['red']}â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•{FIRE_COLORS['orange']}â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
{FIRE_COLORS['red']}â•šâ•â•     {FIRE_COLORS['orange']}â•šâ•â•  â•šâ•â•{FIRE_COLORS['yellow']}â•šâ•â•â•â•â•â• {FIRE_COLORS['red']}â•šâ•â•â•â•â•â• {FIRE_COLORS['orange']}â•šâ•â•â•â•â•â•â•{FIRE_COLORS['reset']}

{FIRE_COLORS['yellow']}              {TOOL_NAME} v{VERSION}{FIRE_COLORS['reset']}
{FIRE_ICONS['author']} {FIRE_COLORS['dark_red']}ä½œè€…: {AUTHOR} | æœ€åæ›´æ–°: {MODIFY_TIME}{FIRE_COLORS['reset']}
{FIRE_SEPARATOR}{FIRE_COLORS['reset']}
    """
    print(banner)
    # æ¨¡æ‹Ÿç«ç„°ç‡ƒçƒ§æ•ˆæœ
    for i in range(3):
        print(f"{FIRE_ICONS['flame']}", end=' ', flush=True)
        time.sleep(0.2)
    print("\n")

# -------------------------- ç¼“å­˜ç®¡ç† --------------------------
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    def __init__(self, cache_dir=CACHE_DIR):
        self.cache_dir = cache_dir
        self.caches = {
            "icp": self._load_cache("icp_cache.json"),
            "ip": self._load_cache("ip_cache.json"),
            "asn": self._load_cache("asn_cache.json"),
            "dns": self._load_cache("dns_cache.json")
        }

    def _load_cache(self, filename):
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        cache_path = os.path.join(self.cache_dir, filename)
        try:
            if os.path.exists(cache_path):
                with open(cache_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"{FIRE_ICONS['warning']} åŠ è½½ç¼“å­˜ {filename} å¤±è´¥: {str(e)}")
        return {}

    def _save_cache(self, cache_type):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        filename = f"{cache_type}_cache.json"
        cache_path = os.path.join(self.cache_dir, filename)
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(self.caches[cache_type], f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"{FIRE_ICONS['warning']} ä¿å­˜ç¼“å­˜ {filename} å¤±è´¥: {str(e)}")

    def get_cached_data(self, cache_type, key):
        """è·å–ç¼“å­˜æ•°æ®ï¼ˆå¸¦è¿‡æœŸæ£€æŸ¥ï¼‰"""
        if cache_type not in self.caches:
            return None
            
        cache_entry = self.caches[cache_type].get(key)
        if not cache_entry:
            return None
            
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        expire_time = CACHE_EXPIRE.get(cache_type, 3600)
        if time.time() - cache_entry['timestamp'] < expire_time:
            return cache_entry['data']
            
        # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
        del self.caches[cache_type][key]
        self._save_cache(cache_type)
        return None

    def set_cached_data(self, cache_type, key, data):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if cache_type not in self.caches:
            return False
            
        self.caches[cache_type][key] = {
            'timestamp': time.time(),
            'data': data
        }
        self._save_cache(cache_type)
        return True

    def save_all_caches(self):
        """ä¿å­˜æ‰€æœ‰ç¼“å­˜"""
        for cache_type in self.caches:
            self._save_cache(cache_type)

# -------------------------- ICPå¤‡æ¡ˆæŸ¥è¯¢æ ¸å¿ƒ --------------------------
class ICPå¤‡æ¡ˆæŸ¥è¯¢å™¨:
    """ICPå¤‡æ¡ˆæŸ¥è¯¢æ ¸å¿ƒç±»"""
    def __init__(self, cache_manager):
        self.cache_manager = cache_manager
        self.base_url = "https://hlwicpfwc.miit.gov.cn/icpproject_query/api"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
            'Origin': 'https://beian.miit.gov.cn',
            'Referer': 'https://beian.miit.gov.cn/',
            'Accept': 'application/json, text/plain, */*',
            'Content-Type': 'application/json;charset=UTF-8'
        }
        self.session = None
        self.token = None
        self.sign = None
        self.uuid = None
        self.initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–ä¼šè¯"""
        if self.initialized:
            return True
            
        # åˆ›å»ºæ–°çš„ä¼šè¯
        self.session = aiohttp.ClientSession(headers=self.headers)
            
        # æœ€å¤šå°è¯•3æ¬¡åˆå§‹åŒ–
        for _ in range(3):
            if await self._setup_session():
                self.initialized = True
                return True
            await asyncio.sleep(2)
            
        logger.warning(f"{FIRE_ICONS['warning']} ICPæŸ¥è¯¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç¼“å­˜å’Œå¤‡ç”¨æº")
        return False

    async def _setup_session(self):
        """è®¾ç½®ä¼šè¯ä¿¡æ¯"""
        try:
            # è·å–åŸºç¡€Cookie
            if not await self._get_base_cookie():
                return False
                
            # è·å–è®¤è¯Token
            if not await self._get_auth_token():
                return False
                
            # å¤„ç†éªŒè¯ç 
            if not await self._handle_captcha():
                return False
                
            return True
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} ä¼šè¯è®¾ç½®å¤±è´¥: {str(e)}")
            return False

    async def _get_base_cookie(self):
        """è·å–åŸºç¡€Cookie"""
        try:
            async with self.session.get("https://beian.miit.gov.cn/") as response:
                cookies = response.cookies
                cookie_str = []
                for cookie in cookies:
                    cookie_str.append(f"{cookie.name}={cookie.value}")
                    if cookie.name.startswith("__jsluid_s"):
                        self.headers['Cookie'] = "; ".join(cookie_str)
                        return True
            logger.warning(f"{FIRE_ICONS['warning']} æœªèƒ½è·å–æœ‰æ•ˆCookie")
            return False
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} è·å–Cookieå¤±è´¥: {str(e)}")
            return False

    async def _get_auth_token(self):
        """è·å–è®¤è¯Token"""
        try:
            timestamp = round(time.time() * 1000)
            auth_secret = f"testtest{timestamp}"
            auth_key = hashlib.md5(auth_secret.encode()).hexdigest()
            
            data = {"authKey": auth_key, "timeStamp": timestamp}
            async with self.session.post(f"{self.base_url}/auth", json=data) as response:
                result = await response.json()
                if result.get("success"):
                    self.token = result["params"]["bussiness"]
                    self.headers['Token'] = self.token
                    return True
            logger.warning(f"{FIRE_ICONS['warning']} æœªèƒ½è·å–æœ‰æ•ˆè®¤è¯Token")
            return False
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} è·å–è®¤è¯Tokenå¤±è´¥: {str(e)}")
            return False

    async def _handle_captcha(self):
        """å¤„ç†éªŒè¯ç """
        try:
            client_uid = self._generate_client_id()
            
            async with self.session.post(
                f"{self.base_url}/image/getCheckImagePoint",
                json=json.loads(client_uid)
            ) as response:
                result = await response.json()
                if not result.get("success"):
                    logger.warning(f"{FIRE_ICONS['warning']} è·å–éªŒè¯ç å›¾ç‰‡å¤±è´¥: {result.get('msg')}")
                    return False
                
                self.uuid = result["params"]["uuid"]
                secret_key = result["params"]["secretKey"]
                self.headers['Uuid'] = self.uuid
                
                point_json = self._solve_captcha(secret_key)
                if not point_json:
                    return False
                
                verify_data = {
                    "token": self.uuid,
                    "secretKey": secret_key,
                    "clientUid": json.loads(client_uid)["clientUid"],
                    "pointJson": point_json
                }
                
                async with self.session.post(
                    f"{self.base_url}/image/checkImage",
                    json=verify_data
                ) as verify_response:
                    verify_result = await verify_response.json()
                    if verify_result.get("success"):
                        self.sign = verify_result["params"]["sign"]
                        self.headers['Sign'] = self.sign
                        return True
                logger.warning(f"{FIRE_ICONS['warning']} éªŒè¯ç éªŒè¯å¤±è´¥: {verify_result.get('msg')}")
                return False
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} å¤„ç†éªŒè¯ç å¤±è´¥: {str(e)}")
            return False

    def _generate_client_id(self):
        """ç”Ÿæˆå®¢æˆ·ç«¯å”¯ä¸€ID"""
        chars = "0123456789abcdef"
        uuid = [random.choice(chars) for _ in range(36)]
        uuid[14] = '4'
        uuid[19] = chars[(3 & int(uuid[19], 16)) | 8]
        uuid[8] = uuid[13] = uuid[18] = uuid[23] = "-"
        return json.dumps({"clientUid": f"point-{''.join(uuid)}"})

    def _solve_captcha(self, secret_key):
        """è§£å†³éªŒè¯ç """
        try:
            points = [
                {"x": 110 + random.randint(-3, 3), "y": 105 + random.randint(-3, 3)},
                {"x": 220 + random.randint(-3, 3), "y": 145 + random.randint(-3, 3)}
            ]
            
            cipher = AES.new(secret_key.encode(), AES.MODE_ECB)
            ciphertext = cipher.encrypt(pad(json.dumps(points).encode(), AES.block_size))
            return base64.b64encode(ciphertext).decode('utf-8')
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} éªŒè¯ç å¤„ç†å¤±è´¥: {str(e)}")
            return None

    async def æŸ¥è¯¢åŸŸåå¤‡æ¡ˆ(self, domain):
        """æŸ¥è¯¢åŸŸåå¤‡æ¡ˆä¿¡æ¯"""
        # 1. å…ˆæ£€æŸ¥ç¼“å­˜
        cached = self.cache_manager.get_cached_data("icp", domain)
        if cached:
            cached['source'] = 'cache'
            return cached
        
        # 2. æå–ä¸»åŸŸå
        main_domain = self._extract_main_domain(domain)
        if not main_domain:
            result = {"has_icp": False, "message": "æ— æ•ˆåŸŸåæ ¼å¼", "source": "local"}
            self.cache_manager.set_cached_data("icp", domain, result)
            return result
        
        # 3. å¤šæºæŸ¥è¯¢ä¸éªŒè¯
        results = []
        
        # ä¼˜å…ˆä½¿ç”¨å·¥ä¿¡éƒ¨å®˜æ–¹æ¥å£
        official_result = await self._query_official_icp(main_domain)
        if official_result:
            results.append((official_result, ICP_QUERY_SOURCES[0]['priority']))
        
        # ä½¿ç”¨ç¬¬ä¸‰æ–¹æ¥å£ä½œä¸ºè¡¥å……
        third_party_result = await self._query_third_party_icp(main_domain)
        if third_party_result:
            results.append((third_party_result, ICP_QUERY_SOURCES[1]['priority']))
        
        # 4. ç»“æœèåˆä¸éªŒè¯
        if not results:
            result = {"has_icp": False, "message": "æ‰€æœ‰æŸ¥è¯¢æºå‡å¤±è´¥", "source": "none"}
            self.cache_manager.set_cached_data("icp", domain, result)
            return result
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œå–æœ€å¯ä¿¡ç»“æœ
        results.sort(key=lambda x: x[1], reverse=True)
        best_result = results[0][0]
        
        # äº¤å‰éªŒè¯
        if len(results) > 1:
            if self._verify_icp_results(best_result, results[1][0]):
                best_result['verified'] = True
            else:
                best_result['verified'] = False
                best_result['conflict_note'] = "ä¸åŒæŸ¥è¯¢æºç»“æœä¸ä¸€è‡´"
        
        self.cache_manager.set_cached_data("icp", domain, best_result)
        return best_result

    async def _query_official_icp(self, domain):
        """é€šè¿‡å®˜æ–¹æ¥å£æŸ¥è¯¢ICPå¤‡æ¡ˆ"""
        try:
            # ç¡®ä¿ä¼šè¯å·²åˆå§‹åŒ–
            if not self.initialized and not await self.initialize():
                return None
                
            # å¤šæ¡ä»¶æŸ¥è¯¢æé«˜å‡†ç¡®æ€§
            for service_type in [1, 0]:  # 1:ç½‘ç«™, 0:å…¨éƒ¨ç±»å‹
                for attempt in range(RETRY_ATTEMPTS):
                    try:
                        data = {
                            "pageNum": 1,
                            "pageSize": 20,
                            "unitName": "",
                            "serviceType": service_type,
                            "domainName": domain
                        }
                        
                        async with self.session.post(
                            f"{self.base_url}/icpAbbreviateInfo/queryByCondition",
                            json=data
                        ) as response:
                            result = await response.json()
                            parsed = self._parse_official_response(result, domain)
                            if parsed:
                                parsed['source'] = 'miit-official'
                                return parsed
                    except Exception as e:
                        logger.warning(f"{FIRE_ICONS['warning']} å®˜æ–¹æ¥å£å°è¯• {attempt+1} å¤±è´¥: {str(e)}")
                        if attempt < RETRY_ATTEMPTS - 1:
                            await asyncio.sleep(1)
            
            # å°è¯•æŒ‰å•ä½åç§°æŸ¥è¯¢
            domain_prefix = domain.split('.')[0] if '.' in domain else domain
            data = {
                "pageNum": 1,
                "pageSize": 20,
                "unitName": domain_prefix,
                "serviceType": 1
            }
            
            async with self.session.post(
                f"{self.base_url}/icpAbbreviateInfo/queryByCondition",
                json=data
            ) as response:
                result = await response.json()
                parsed = self._parse_official_response(result, domain)
                if parsed:
                    parsed['source'] = 'miit-official'
                    return parsed
                    
            return {"has_icp": False, "message": "æœªæ‰¾åˆ°å¤‡æ¡ˆä¿¡æ¯", "source": "miit-official"}
            
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} å®˜æ–¹ICPæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    async def _query_third_party_icp(self, domain):
        """é€šè¿‡ç¬¬ä¸‰æ–¹æ¥å£æŸ¥è¯¢ICPå¤‡æ¡ˆ"""
        try:
            # ç¬¬ä¸‰æ–¹APIç¤ºä¾‹
            third_party_url = f"https://api.example.com/icp?domain={domain}"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(third_party_url, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get("status") == "success" and data.get("has_icp"):
                            return {
                                "has_icp": True,
                                "domain": domain,
                                "license": data.get("license", "æœªçŸ¥"),
                                "unit": data.get("unit", "æœªçŸ¥"),
                                "website_name": data.get("website_name", "æœªçŸ¥"),
                                "update_time": data.get("update_time", "æœªçŸ¥"),
                                "source": "third-party"
                            }
                        else:
                            return {
                                "has_icp": False,
                                "message": data.get("message", "æœªæ‰¾åˆ°å¤‡æ¡ˆä¿¡æ¯"),
                                "source": "third-party"
                            }
            return {"has_icp": False, "message": "ç¬¬ä¸‰æ–¹æ¥å£æŸ¥è¯¢å¤±è´¥", "source": "third-party"}
        except Exception as e:
            logger.warning(f"{FIRE_ICONS['warning']} ç¬¬ä¸‰æ–¹ICPæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    def _parse_official_response(self, response_data, domain):
        """è§£æå®˜æ–¹æ¥å£å“åº”"""
        try:
            if response_data.get("code") != 200:
                return {"has_icp": False, "message": response_data.get("msg", "æŸ¥è¯¢å¤±è´¥")}
                
            params = response_data.get("params", {})
            records = params.get("list", [])
            
            if not records:
                return {"has_icp": False, "message": "æœªæ‰¾åˆ°å¤‡æ¡ˆä¿¡æ¯"}
            
            # ç²¾ç¡®åŒ¹é…åŸŸå
            domain_parts = tldextract.extract(domain)
            main_domain = f"{domain_parts.domain}.{domain_parts.suffix}"
            matched_records = []
            
            for record in records:
                record_domain = str(record.get("domain", "")).lower()
                record_parts = tldextract.extract(record_domain)
                record_main = f"{record_parts.domain}.{record_parts.suffix}"
                
                if record_main == main_domain:
                    matched_records.append(record)
            
            # é€‰æ‹©æœ€ä½³åŒ¹é…
            if matched_records:
                best_record = matched_records[0]
            else:
                best_record = records[0]
            
            return {
                "has_icp": True,
                "domain": domain,
                "main_domain": main_domain,
                "license": best_record.get("serviceLicence", "æœªçŸ¥"),
                "unit": best_record.get("unitName", "æœªçŸ¥"),
                "unit_type": best_record.get("unitType", "æœªçŸ¥"),
                "website_name": best_record.get("serviceName", "æœªçŸ¥"),
                "website_type": best_record.get("serviceType", "æœªçŸ¥"),
                "update_time": best_record.get("updateRecordTime", "æœªçŸ¥"),
                "matched_count": len(matched_records) if matched_records else 1
            }
            
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} è§£æå¤‡æ¡ˆä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"has_icp": False, "message": f"è§£æé”™è¯¯: {str(e)}"}

    def _extract_main_domain(self, domain):
        """æå–ä¸»åŸŸå"""
        try:
            ext = tldextract.extract(domain)
            if ext.domain and ext.suffix:
                return f"{ext.domain}.{ext.suffix}"
            
            parsed = urlparse(domain)
            if parsed.netloc:
                return parsed.netloc.split(':')[0]
            return domain.split('/')[0].split(':')[0]
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} æå–ä¸»åŸŸåå¤±è´¥: {str(e)}")
            return domain

    def _verify_icp_results(self, result1, result2):
        """éªŒè¯ä¸¤ä¸ªå¤‡æ¡ˆæŸ¥è¯¢ç»“æœæ˜¯å¦ä¸€è‡´"""
        if not result1.get("has_icp") or not result2.get("has_icp"):
            return result1.get("has_icp") == result2.get("has_icp")
            
        # å…³é”®ä¿¡æ¯åŒ¹é…åº¦
        match_count = 0
        total_checks = 0
        
        # æ£€æŸ¥è®¸å¯è¯å·
        if result1.get("license") and result2.get("license"):
            total_checks += 1
            if result1["license"] in result2["license"] or result2["license"] in result1["license"]:
                match_count += 1
        
        # æ£€æŸ¥ä¸»åŠå•ä½
        if result1.get("unit") and result2.get("unit"):
            total_checks += 1
            if result1["unit"] in result2["unit"] or result2["unit"] in result1["unit"]:
                match_count += 1
        
        # æ£€æŸ¥ç½‘ç«™åç§°
        if result1.get("website_name") and result2.get("website_name"):
            total_checks += 1
            if result1["website_name"] in result2["website_name"] or result2["website_name"] in result1["website_name"]:
                match_count += 1
        
        # åŒ¹é…åº¦è¶…è¿‡60%è§†ä¸ºä¸€è‡´
        return total_checks == 0 or (match_count / total_checks) > 0.6

    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self.session:
            await self.session.close()
            self.session = None
        self.initialized = False

# -------------------------- IPä¸ç½‘ç»œä¿¡æ¯æŸ¥è¯¢æ ¸å¿ƒ --------------------------
class IPä¿¡æ¯æŸ¥è¯¢å™¨:
    """IPä¿¡æ¯æŸ¥è¯¢å™¨"""
    def __init__(self, cache_manager):
        self.cache_manager = cache_manager
        self.session = None

    async def åˆå§‹åŒ–ä¼šè¯(self):
        """åˆå§‹åŒ–ä¼šè¯"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        return True

    async def æŸ¥è¯¢IPä¿¡æ¯(self, ip):
        """æŸ¥è¯¢IPä¿¡æ¯"""
        # ç¡®ä¿ä¼šè¯å·²åˆå§‹åŒ–
        await self.åˆå§‹åŒ–ä¼šè¯()
        
        # 1. æ£€æŸ¥ç¼“å­˜
        cached = self.cache_manager.get_cached_data("ip", ip)
        if cached:
            cached['source'] = 'cache'
            return cached
        
        # 2. å¤šæºæŸ¥è¯¢
        results = []
        for api in IP_INFO_APIS:
            try:
                result = await self._query_ip_api(api, ip)
                if result:
                    results.append((result, api))
                    if api.get("reliable", False):
                        break
            except Exception as e:
                logger.warning(f"{FIRE_ICONS['warning']} API {api['name']} æŸ¥è¯¢å¤±è´¥: {str(e)}")
                continue
        
        # 3. èåˆç»“æœæé«˜å‡†ç¡®æ€§
        if not results:
            result = {
                "ip": ip,
                "country": "æœªçŸ¥",
                "region": "æœªçŸ¥",
                "city": "æœªçŸ¥",
                "isp": "æœªçŸ¥",
                "org": "æœªçŸ¥",
                "asn": "æœªçŸ¥",
                "as_name": "æœªçŸ¥",
                "source": "none"
            }
            self.cache_manager.set_cached_data("ip", ip, result)
            return result
        
        # 4. ç»“æœèåˆä¸éªŒè¯
        fused_result = self._fuse_ip_results(results)
        self.cache_manager.set_cached_data("ip", ip, fused_result)
        return fused_result

    async def _query_ip_api(self, api_config, ip):
        """æŸ¥è¯¢å•ä¸ªIPä¿¡æ¯API"""
        try:
            url = api_config["url"].format(target=ip)
            async with self.session.get(url, timeout=api_config["timeout"]) as response:
                if response.status != 200:
                    return None
                    
                data = await response.json()
                
                # æ£€æŸ¥APIç‰¹å®šçš„æˆåŠŸæ¡ä»¶
                if "success_key" in api_config:
                    if data.get(api_config["success_key"]) != api_config["success_value"]:
                        return None
                
                # æå–æ•°æ®
                result = {}
                mapping = api_config["mapping"]
                
                # å¦‚æœAPIè¿”å›çš„æ•°æ®åµŒå¥—åœ¨ç‰¹å®šé”®ä¸‹
                if "data_key" in api_config:
                    data = data.get(api_config["data_key"], {})
                
                # æ˜ å°„å­—æ®µ
                for key, source in mapping.items():
                    if callable(source):
                        result[key] = source(data)
                    elif source is not None:
                        result[key] = data.get(source, "æœªçŸ¥")
                    else:
                        result[key] = "æœªçŸ¥"
                
                # ç¡®ä¿IPå­—æ®µå­˜åœ¨
                if "ip" not in result or not result["ip"]:
                    result["ip"] = ip
                    
                result["source"] = api_config["name"]
                return result
                
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} IPæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    def _fuse_ip_results(self, results):
        """èåˆå¤šä¸ªAPIçš„IPæŸ¥è¯¢ç»“æœ"""
        # ç»“æœæ ¼å¼æ¨¡æ¿
        fused = {
            "ip": results[0][0]["ip"],
            "country": [],
            "region": [],
            "city": [],
            "isp": [],
            "org": [],
            "asn": [],
            "as_name": [],
            "sources": []
        }
        
        # æ”¶é›†æ‰€æœ‰ç»“æœ
        for result, api in results:
            fused["sources"].append(api["name"])
            for key in ["country", "region", "city", "isp", "org", "asn", "as_name"]:
                if result.get(key) and result[key] not in ["æœªçŸ¥", "", None]:
                    fused[key].append(result[key])
        
        # æŒ‰å‡ºç°é¢‘ç‡é€‰æ‹©æœ€å¯èƒ½çš„å€¼
        final = {"ip": fused["ip"], "sources": ", ".join(fused["sources"])}
        for key in ["country", "region", "city", "isp", "org", "asn", "as_name"]:
            if fused[key]:
                # é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼
                final[key] = max(set(fused[key]), key=fused[key].count)
            else:
                final[key] = "æœªçŸ¥"
        
        return final

    async def è§£æåŸŸåIP(self, domain):
        """è§£æåŸŸåIP"""
        # ç¡®ä¿ä¼šè¯å·²åˆå§‹åŒ–
        await self.åˆå§‹åŒ–ä¼šè¯()
        
        # 1. æ£€æŸ¥ç¼“å­˜
        cached = self.cache_manager.get_cached_data("dns", domain)
        if cached:
            return cached
        
        # 2. å¤šæ–¹æ³•è§£ææé«˜å‡†ç¡®æ€§
        ips = set()
        
        # æ–¹æ³•1: ä½¿ç”¨ç³»ç»ŸDNSè§£æ
        try:
            addr_info = socket.getaddrinfo(domain, None, socket.AF_INET)
            for info in addr_info:
                ips.add(info[4][0])
        except Exception as e:
            logger.warning(f"{FIRE_ICONS['warning']} DNSè§£æå¤±è´¥: {str(e)}")
        
        # 3. å¤„ç†ç»“æœ
        ip_list = list(ips) if ips else []
        result = {
            "domain": domain,
            "ips": ip_list,
            "primary_ip": ip_list[0] if ip_list else None,
            "ip_count": len(ip_list),
            "is_cdn": len(ip_list) > 3  # ç®€å•åˆ¤æ–­æ˜¯å¦ä¸ºCDN
        }
        
        self.cache_manager.set_cached_data("dns", domain, result)
        return result

    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self.session:
            await self.session.close()
            self.session = None

# -------------------------- æ‰«ææ ¸å¿ƒåŠŸèƒ½ --------------------------
class URLæ‰«æå™¨:
    """URLæ‰«æå™¨ï¼ˆç«ç„°ç‰ˆï¼‰"""
    def __init__(self, cache_manager, enable_icp=True, workers=DEFAULT_WORKERS, timeout=DEFAULT_TIMEOUT):
        self.cache_manager = cache_manager
        self.enable_icp = enable_icp
        self.workers = workers
        self.timeout = timeout
        self.icpæŸ¥è¯¢å™¨ = ICPå¤‡æ¡ˆæŸ¥è¯¢å™¨(cache_manager) if enable_icp else None
        self.ipæŸ¥è¯¢å™¨ = IPä¿¡æ¯æŸ¥è¯¢å™¨(cache_manager)
        self.results = []

    async def åˆå§‹åŒ–(self):
        """åˆå§‹åŒ–æ‰«æå™¨"""
        await self.ipæŸ¥è¯¢å™¨.åˆå§‹åŒ–ä¼šè¯()
        if self.enable_icp and self.icpæŸ¥è¯¢å™¨:
            await self.icpæŸ¥è¯¢å™¨.initialize()
        return True

    async def æ‰«æå•ä¸ªURL(self, url):
        """æ‰«æå•ä¸ªURL"""
        # æ ‡å‡†åŒ–URL
        normalized_url = self._æ ‡å‡†åŒ–URL(url)
        if not normalized_url:
            logger.warning(f"{FIRE_ICONS['warning']} æ— æ•ˆURL: {url}")
            return None

        parsed_url = urlparse(normalized_url)
        hostname = parsed_url.netloc
        
        # åˆå§‹åŒ–ç»“æœ
        result = {
            'original_url': url,
            'normalized_url': normalized_url,
            'hostname': hostname,
            'check_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'dns_info': {},
            'ip_info': {},
            'http': {},
            'https': {},
            'icp_info': {}
        }

        # 1. è§£æDNSä¿¡æ¯
        logger.info(f"{FIRE_ICONS['ip']} æ­£åœ¨è§£æ {hostname} çš„IPåœ°å€...")
        dns_info = await self.ipæŸ¥è¯¢å™¨.è§£æåŸŸåIP(hostname)
        result['dns_info'] = dns_info
        
        # 2. è·å–IPä¿¡æ¯ï¼ˆå¦‚æœæœ‰IPï¼‰
        if dns_info['primary_ip']:
            logger.info(f"{FIRE_ICONS['asn']} æ­£åœ¨æŸ¥è¯¢ {dns_info['primary_ip']} çš„ASNå’Œè¿è¥å•†ä¿¡æ¯...")
            ip_info = await self.ipæŸ¥è¯¢å™¨.æŸ¥è¯¢IPä¿¡æ¯(dns_info['primary_ip'])
            result['ip_info'] = ip_info
        
        # 3. æ£€æŸ¥HTTPå’ŒHTTPSå¯ç”¨æ€§
        logger.info(f"{FIRE_ICONS['check']} æ­£åœ¨æ£€æŸ¥ {hostname} çš„è¿æ¥æ€§...")
        result['http'] = await self._æ£€æŸ¥URLåè®®(normalized_url, 'http')
        result['https'] = await self._æ£€æŸ¥URLåè®®(normalized_url, 'https')
        
        # 4. æŸ¥è¯¢ICPå¤‡æ¡ˆä¿¡æ¯
        if self.enable_icp and self.icpæŸ¥è¯¢å™¨ and hostname:
            logger.info(f"{FIRE_ICONS['icp']} æ­£åœ¨æŸ¥è¯¢ {hostname} çš„ICPå¤‡æ¡ˆä¿¡æ¯...")
            result['icp_info'] = await self.icpæŸ¥è¯¢å™¨.æŸ¥è¯¢åŸŸåå¤‡æ¡ˆ(hostname)

        return result

    def _æ ‡å‡†åŒ–URL(self, url):
        """æ ‡å‡†åŒ–URLæ ¼å¼"""
        if not url or not isinstance(url, str):
            return None
            
        url = url.strip()
        parsed = urlparse(url)
        
        # å¤„ç†æ— åè®®URL
        if not parsed.scheme:
            for scheme in ['https', 'http']:
                test_url = f"{scheme}://{url}"
                if self._éªŒè¯URL(test_url):
                    return test_url
            return None
            
        if parsed.scheme not in ['http', 'https']:
            return None
            
        return urlunparse(parsed)

    def _éªŒè¯URL(self, url):
        """éªŒè¯URLæ ¼å¼æ˜¯å¦æœ‰æ•ˆ"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except:
            return False

    async def _æ£€æŸ¥URLåè®®(self, url, protocol):
        """æ£€æŸ¥æŒ‡å®šåè®®çš„URLå¯ç”¨æ€§"""
        parsed = urlparse(url)
        target_url = urlunparse((protocol, parsed.netloc, parsed.path, 
                                parsed.params, parsed.query, parsed.fragment))
        
        result = {
            'url': target_url,
            'status_code': None,
            'is_accessible': False,
            'error': None,
            'redirect_count': 0,
            'final_url': target_url,
            'response_time': None
        }
        
        try:
            start_time = time.time()
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    target_url, 
                    timeout=self.timeout, 
                    allow_redirects=True,
                    headers=headers,
                    ssl=False
                ) as response:
                    result['response_time'] = round(time.time() - start_time, 3)
                    result['status_code'] = response.status
                    result['is_accessible'] = response.status == 200
                    result['redirect_count'] = len(response.history)
                    result['final_url'] = str(response.url)
            
        except Exception as e:
            result['error'] = str(e)
            result['response_time'] = round(time.time() - start_time, 3)
            
        return result

    async def æ‰¹é‡æ‰«æ(self, urls):
        """æ‰¹é‡æ‰«æURLåˆ—è¡¨"""
        # åˆå§‹åŒ–æ‰«æå™¨
        await self.åˆå§‹åŒ–()
        
        # å¤„ç†URLåˆ—è¡¨
        valid_urls = [url for url in urls if self._æ ‡å‡†åŒ–URL(url)]
        if not valid_urls:
            logger.warning(f"{FIRE_ICONS['warning']} æ²¡æœ‰æœ‰æ•ˆURLå¯æ‰«æ")
            return []
            
        logger.info(f"{FIRE_ICONS['info']} å¼€å§‹æ‰¹é‡æ‰«æ {len(valid_urls)} ä¸ªURL")
        
        # å¹¶å‘æ‰«æ
        tasks = [self.æ‰«æå•ä¸ªURL(url) for url in valid_urls]
        for future in asyncio.as_completed(tasks):
            result = await future
            if result:
                self.results.append(result)
                self._æ˜¾ç¤ºæ‰«æè¿›åº¦(result)
                # æ·»åŠ å»¶è¿Ÿæ§åˆ¶æ‰“å°é€Ÿåº¦
                await asyncio.sleep(PRINT_DELAY)
        
        # ä¿å­˜ç»“æœåˆ°CSV
        self._ä¿å­˜ç»“æœåˆ°CSV()
        
        return self.results

    def _æ˜¾ç¤ºæ‰«æè¿›åº¦(self, result):
        """æ˜¾ç¤ºæ‰«æè¿›åº¦ä¿¡æ¯"""
        hostname = result['hostname']
        ip = result['dns_info']['primary_ip'] or 'æœªçŸ¥IP'
        asn = result['ip_info'].get('asn', 'æœªçŸ¥ASN')
        isp = result['ip_info'].get('isp', 'æœªçŸ¥è¿è¥å•†')
        
        https_status = f"{FIRE_ICONS['success']}" if result['https']['is_accessible'] else f"{FIRE_ICONS['error']}"
        http_status = f"{FIRE_ICONS['success']}" if result['http']['is_accessible'] else f"{FIRE_ICONS['error']}"
        
        icp_status = "æœªæŸ¥è¯¢"
        if self.enable_icp and result['icp_info']:
            icp_status = f"{FIRE_ICONS['success']}å·²å¤‡æ¡ˆ" if result['icp_info'].get('has_icp') else f"{FIRE_ICONS['warning']}æœªå¤‡æ¡ˆ"
        
        # ç«ç„°é£æ ¼çš„è¿›åº¦æ˜¾ç¤º
        line = f"{FIRE_ICONS['flame']} {https_status} HTTPS | {http_status} HTTP | {ip} | AS{asn} | {isp} | {hostname} | ICP: {icp_status}"
        print(line)

    def _ä¿å­˜ç»“æœåˆ°CSV(self):
        """ä¿å­˜æ‰«æç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆä¿®å¤ä¿å­˜é—®é¢˜ï¼‰"""
        if not self.results:
            logger.info(f"{FIRE_ICONS['info']} æ²¡æœ‰ç»“æœå¯ä¿å­˜")
            return None
            
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(CSV_OUTPUT_DIR):
            try:
                os.makedirs(CSV_OUTPUT_DIR, exist_ok=True)
            except Exception as e:
                logger.error(f"{FIRE_ICONS['error']} æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {str(e)}")
                return None
        
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        csv_filename = f"fire_scan_result_{timestamp}.csv"
        csv_path = os.path.join(CSV_OUTPUT_DIR, csv_filename)
        
        # å®šä¹‰CSVå­—æ®µ
        fieldnames = [
            'original_url', 'normalized_url', 'hostname', 
            'primary_ip', 'all_ips', 'is_cdn',
            'ip_country', 'ip_region', 'ip_city', 
            'isp', 'org', 'asn', 'as_name', 'ip_sources',
            'https_url', 'https_status', 'https_accessible', 'https_response_time', 'https_error',
            'http_url', 'http_status', 'http_accessible', 'http_response_time', 'http_error',
            'icp_has_record', 'icp_license', 'icp_unit', 'icp_website_name',
            'icp_update_time', 'icp_source', 'icp_verified', 'icp_message',
            'check_time'
        ]
        
        try:
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for result in self.results:
                    icp_info = result.get('icp_info', {})
                    dns_info = result.get('dns_info', {})
                    ip_info = result.get('ip_info', {})
                    
                    writer.writerow({
                        'original_url': result['original_url'],
                        'normalized_url': result['normalized_url'],
                        'hostname': result['hostname'],
                        'primary_ip': dns_info.get('primary_ip', ''),
                        'all_ips': ', '.join(dns_info.get('ips', [])),
                        'is_cdn': dns_info.get('is_cdn', False),
                        'ip_country': ip_info.get('country', ''),
                        'ip_region': ip_info.get('region', ''),
                        'ip_city': ip_info.get('city', ''),
                        'isp': ip_info.get('isp', ''),
                        'org': ip_info.get('org', ''),
                        'asn': ip_info.get('asn', ''),
                        'as_name': ip_info.get('as_name', ''),
                        'ip_sources': ip_info.get('sources', ''),
                        'https_url': result['https']['url'],
                        'https_status': result['https']['status_code'] or '',
                        'https_accessible': result['https']['is_accessible'],
                        'https_response_time': result['https']['response_time'],
                        'https_error': result['https']['error'] or '',
                        'http_url': result['http']['url'],
                        'http_status': result['http']['status_code'] or '',
                        'http_accessible': result['http']['is_accessible'],
                        'http_response_time': result['http']['response_time'],
                        'http_error': result['http']['error'] or '',
                        'icp_has_record': icp_info.get('has_icp', False),
                        'icp_license': icp_info.get('license', ''),
                        'icp_unit': icp_info.get('unit', ''),
                        'icp_website_name': icp_info.get('website_name', ''),
                        'icp_update_time': icp_info.get('update_time', ''),
                        'icp_source': icp_info.get('source', ''),
                        'icp_verified': icp_info.get('verified', ''),
                        'icp_message': icp_info.get('message', ''),
                        'check_time': result['check_time']
                    })
            
            logger.info(f"{FIRE_ICONS['csv']} æ‰«æç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
            return csv_path
            
        except PermissionError:
            logger.error(f"{FIRE_ICONS['error']} æ²¡æœ‰æƒé™å†™å…¥æ–‡ä»¶: {csv_path}")
            return None
        except Exception as e:
            logger.error(f"{FIRE_ICONS['error']} ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

    async def å…³é—­(self):
        """å…³é—­æ‰«æå™¨èµ„æºï¼ˆä¿®å¤äº‹ä»¶å¾ªç¯é”™è¯¯ï¼‰"""
        # ç¡®ä¿æ‰€æœ‰ä¼šè¯éƒ½æ­£ç¡®å…³é—­
        if self.icpæŸ¥è¯¢å™¨:
            await self.icpæŸ¥è¯¢å™¨.close()
        await self.ipæŸ¥è¯¢å™¨.close()
        self.cache_manager.save_all_caches()

# -------------------------- ä¸»ç¨‹åºå…¥å£ --------------------------
def è¯»å–URLæ–‡ä»¶(file_path):
    """ä»æ–‡ä»¶è¯»å–URLåˆ—è¡¨"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    except Exception as e:
        logger.error(f"{FIRE_ICONS['error']} è¯»å–URLæ–‡ä»¶å¤±è´¥: {str(e)}")
        return []

async def å®‰å…¨ä¸»æµç¨‹():
    """å®‰å…¨çš„ä¸»æµç¨‹åŒ…è£…ï¼Œé˜²æ­¢äº‹ä»¶å¾ªç¯é”™è¯¯"""
    # æ‰“å°ç«ç„°Banner
    æ‰“å°ç«ç„°Banner()
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = CacheManager()
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦å¯ç”¨ICPæŸ¥è¯¢
    icp_choice = input(f"{FIRE_ICONS['icp']} æ˜¯å¦æŸ¥è¯¢ICPå¤‡æ¡ˆä¿¡æ¯? (y/nï¼Œé»˜è®¤y): ").strip().lower()
    enable_icp = icp_choice != 'n'  # é»˜è®¤å¯ç”¨
    
    # é€‰æ‹©æ‰«ææ¨¡å¼
    print("\nè¯·é€‰æ‹©æ‰«ææ¨¡å¼:")
    print("1. æ‰¹é‡URLæ‰«æï¼ˆä»æ–‡ä»¶è¯»å–ï¼‰")
    print("2. å•ä¸ªURLæ‰«æ")
    
    choice = input("è¯·é€‰æ‹© (1/2): ").strip()
    
    # åˆå§‹åŒ–æ‰«æå™¨
    scanner = URLæ‰«æå™¨(cache_manager, enable_icp=enable_icp)
    
    try:
        if choice == '1':
            # æ‰¹é‡æ‰«æ
            file_path = input("è¯·è¾“å…¥åŒ…å«URLçš„æ–‡ä»¶è·¯å¾„: ").strip()
            if not os.path.exists(file_path):
                logger.error(f"{FIRE_ICONS['error']} æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return
                
            urls = è¯»å–URLæ–‡ä»¶(file_path)
            if not urls:
                logger.error(f"{FIRE_ICONS['error']} æœªä»æ–‡ä»¶ä¸­è¯»å–åˆ°æœ‰æ•ˆURL")
                return
                
            await scanner.æ‰¹é‡æ‰«æ(urls)
            
        elif choice == '2':
            # å•ä¸ªURLæ‰«æ
            url = input("è¯·è¾“å…¥è¦æ‰«æçš„URL: ").strip()
            if not url:
                logger.error(f"{FIRE_ICONS['error']} URLä¸èƒ½ä¸ºç©º")
                return
                
            result = await scanner.æ‰«æå•ä¸ªURL(url)
            if result:
                scanner.results.append(result)
                scanner._ä¿å­˜ç»“æœåˆ°CSV()
                
        else:
            logger.error(f"{FIRE_ICONS['error']} æ— æ•ˆé€‰æ‹©")
            return
            
        # æ˜¾ç¤ºæ‰«ææ€»ç»“
        print(f"\n{FIRE_SEPARATOR}{FIRE_COLORS['reset']}")
        print(f"{FIRE_ICONS['info']} æ‰«æå®Œæˆ:")
        print(f"æ€»URLæ•°: {len(scanner.results)}")
        
        https_ok = sum(1 for r in scanner.results if r['https']['is_accessible'])
        http_ok = sum(1 for r in scanner.results if r['http']['is_accessible'])
        print(f"å¯è®¿é—®URLæ•°: {https_ok + http_ok} (HTTPS: {https_ok}, HTTP: {http_ok})")
        
        if enable_icp:
            icp_count = sum(1 for r in scanner.results if r['icp_info'].get('has_icp', False))
            print(f"å·²å¤‡æ¡ˆåŸŸåæ•°: {icp_count}")
        
        cdn_count = sum(1 for r in scanner.results if r['dns_info'].get('is_cdn', False))
        print(f"ç–‘ä¼¼CDNåŠ é€ŸåŸŸåæ•°: {cdn_count}")
        
        print(f"\n{FIRE_ICONS['author']} å·¥å…·ä½œè€…: {AUTHOR}")
        print(f"{FIRE_SEPARATOR}{FIRE_COLORS['reset']}")
        
    finally:
        # ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾
        await scanner.å…³é—­()

def ä¸»å‡½æ•°():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†äº‹ä»¶å¾ªç¯"""
    try:
        # ä½¿ç”¨åˆé€‚çš„äº‹ä»¶å¾ªç¯ç­–ç•¥
        if sys.platform.startswith('win'):
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        
        asyncio.run(å®‰å…¨ä¸»æµç¨‹())
        
    except KeyboardInterrupt:
        logger.info(f"\n{FIRE_ICONS['info']} ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"{FIRE_ICONS['error']} ç¨‹åºå¼‚å¸¸é€€å‡º: {str(e)}")
    sys.exit(0)

if __name__ == "__main__":
    ä¸»å‡½æ•°()
    
